# -*- coding: utf-8 -*-
"""Titanic prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KoVt1HXqvFwhPwi54_vOKwpvsmbsuCeV

Titanic : Machine Learning from Disaster
"""

! mkdir -p /root/.kaggle
! mv  kaggle.json /root/.kaggle/

!ls -lA /root/.kaggle

import kaggle

!kaggle competitions download -c titanic

"""collecting the train and test data and importing libraries"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import warnings
warnings.simplefilter(action='ignore')

titanic_data = pd.read_csv("train.csv")

"""EDA - exploratary data analysis"""

titanic_data.head()

# survived = 0-no,1-yes
#pclass = ticket class(1st,2nd,3rd)
#sibsp = sibilings and spouses aboard the titanic
#parch = parents and childrens aboard the titanic
#ticket = ticket number
#cabin = cabin number
#embarked =  port of embarkation, C= cherbourg,Q-queenstown,S- southmpton

titanic_data.describe()

titanic_data.info()

titanic_data['Survived'].value_counts()  #checking unique values

titanic_data['Pclass'].value_counts()

titanic_data['Sex'].value_counts()

titanic_data['SibSp'].value_counts()

titanic_data['Parch'].value_counts()

titanic_data['Embarked'].value_counts()

#data visualization
sns.countplot(titanic_data['Sex'])

sns.barplot(titanic_data['Survived'],titanic_data['Sex'])

sns.barplot(titanic_data['Survived'],titanic_data['Fare'],titanic_data['Pclass'])

#remove outliers
sns.boxplot(x=titanic_data['Fare'])
plt.show()

"""we can see the majority of passengers Fare is less than 250 
so,lets keep the rows only <250
"""

titanic_data=titanic_data[titanic_data['Fare']<250]
titanic_data.shape

sns.boxplot(x=titanic_data['Age'])
plt.show()

#we can see here some outliers but not so much far so, we are not changing rows

"""fill NUll values"""

titanic_data.isnull().sum()

"""177 null values in age column and 686 null values in cabin column"""

titanic_data.drop(columns='Cabin',axis=1,inplace=True) #remove cabin column

titanic_data.shape

"""fill all the null values in age column with mean"""

age_mean =  titanic_data['Age'].mean()
age_mean

titanic_data['Age'].fillna(age_mean,inplace=True)

titanic_data.isnull().sum()

titanic_data['Embarked'].value_counts()

titanic_data['Embarked'].fillna('S',inplace=True)

titanic_data.isnull().sum() #there is no null values

"""feature engineering"""

titanic_data.head(10)

titanic_data['total_family members'] = titanic_data['SibSp']+titanic_data['Parch']+1
titanic_data['Alone'] = titanic_data['total_family members'].apply(lambda x:0 if x>1 else 1)

titanic_data.head(10)

sns.barplot(titanic_data['total_family members'],titanic_data['Survived'])

sns.barplot(titanic_data['Alone'],titanic_data['Survived'])

def age_to_group(age):
 if 0 < age< 12: #children
   return 0
 if 12<=age<50:  #adult
   return 1
 if age>=50: #elderly person
    return 2

titanic_data['age_to_group']=titanic_data['Age'].apply(age_to_group)

titanic_data.head(10)

sns.barplot(titanic_data['age_to_group'],titanic_data['Survived'])

"""we can capture name_title as Mr,Miss,Ms etc.."""

titanic_data['Name_title']= titanic_data['Name'].str.extract(' ([A-Za-z]+)\.',expand = False)

titanic_data.head()

titanic_data['Name_title'].value_counts()

def clean_Name_title(val):
  if val in ['Rev','Mlle','Col','Ms','Capt','Lady','Countess','Mme','Don','Jonkheer','Sir']:
    return 'RARE'
  else:
    return val

titanic_data['Name_title']=titanic_data['Name_title'].apply(clean_Name_title)

titanic_data['Name_title'].value_counts()

sns.barplot(titanic_data['Name_title'],titanic_data['Survived'])

titanic_data.head() #drop useless columns

#save the targer column
target =  titanic_data['Survived'].tolist()

titanic_data.drop(['PassengerId','Survived','Name','Ticket','clean_Name_title'],axis=1,inplace=True)

titanic_data.head()

"""convert all the columns in numeric form using label encoder(embarked,name_title,sex columns)"""

from sklearn import preprocessing
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

import random,os

le = preprocessing.LabelEncoder()
titanic_data['Sex']=le.fit_transform(titanic_data['Sex'])
titanic_data['Embarked']=le.fit_transform(titanic_data['Embarked'])
titanic_data['Name_title']=le.fit_transform(titanic_data['Name_title'])
titanic_data.head()

"""train our data using logisticregression 
so dividing our data into train and validation
"""

train_data,val_data,train_target,val_target = train_test_split(titanic_data,target,test_size = 0.2)

train_data.shape , val_data.shape ,len(train_target),len(val_target)

def seed_everything(seed):
  random.seed(seed)
  np.random.seed(seed)
  os.environ['PYTHONHASHSEED']= str(seed)
  seed_everything(2020)

model = LogisticRegression()
model.fit(train_data,train_target)

"""validation"""

val_predictions = model.predict(val_data)

len(val_predictions)

#first 10 values of validations predictions
val_predictions[:10]

accuracy = accuracy_score(val_target,val_predictions)

accuracy

print("We got %.3f percent accuracy on our validation unseen data !!"%(accuracy*100))
print("We are #.3f correct in predicting whether a person will survice in Titanic crash !!"%(accuracy*100))